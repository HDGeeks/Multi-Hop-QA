{
  "micro_overall": {
    "exact_match_percent": 0.0,
    "f1_percent": 56.70489232989233,
    "n": 600
  },
  "by_setting": {
    "gold": {
      "exact_match_percent": 0.0,
      "f1_percent": 58.394227994228,
      "n": 150
    },
    "para": {
      "exact_match_percent": 0.0,
      "f1_percent": 55.34184704184704,
      "n": 150
    },
    "dist": {
      "exact_match_percent": 0.0,
      "f1_percent": 57.635286935286935,
      "n": 150
    },
    "para_dist": {
      "exact_match_percent": 0.0,
      "f1_percent": 55.44820734820735,
      "n": 150
    }
  },
  "paths": {
    "per_run_csv": "/Users/hd/Desktop/Multi-Hop-QA/src/results_test/llama31_8b/metrics/per_run_v2.csv",
    "aggregated_items_csv": "/Users/hd/Desktop/Multi-Hop-QA/src/results_test/llama31_8b/metrics/aggregated_items_v2.csv",
    "summary_csv": "/Users/hd/Desktop/Multi-Hop-QA/src/results_test/llama31_8b/metrics/summary_v2.csv"
  }
}